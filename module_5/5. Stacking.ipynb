{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vecstack import stacking\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используемые для стекинга модели, такие как RandomForestRegressor, ExtraTreesRegressor принимают на вход лишь числовые переменные и не умеют работать с категориальными, поэтому необходимо сделать преобразование категориальных признаков:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прочитаем данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_stack_tax.csv')\n",
    "test = pd.read_csv('test_stack_tax.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделим категориальные признаки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features_ids = np.where(train.dtypes == object)[0].tolist()\n",
    "cat_features_ids.append(5)\n",
    "cat_features_ids.extend([i for i in range(16, 71)])\n",
    "categorical_features_names = list(train.columns[cat_features_ids])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объединим тренировочный и тестовый датасеты для dummy-кодирования, добавив столбец price = 0 в тестовую выборку и столбец sample = {0,1} в обе выборки для их разделения в дальнейшем:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['sample'] = 1\n",
    "test['sample'] = 0\n",
    "test['price'] = 0\n",
    "data = test.append(train, sort=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18417, 73), (3837, 73), (22254, 73))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape, data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем dummy-кодирование для всех категориальных переменных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in categorical_features_names:\n",
    "    dummies_train = pd.get_dummies(data[column], prefix=data[column].name)\n",
    "    data = data.drop(data[column].name, axis=1).join(dummies_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22254, 369)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем разделение на тренировочную и тестовую выборки, а также удалим столбцы sample из обеих выборок и фиктивный столбец price из тестовой: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data[data[\"sample\"] == 1]\n",
    "test = data[data[\"sample\"] == 0]\n",
    "train.drop(columns=[\"sample\"], inplace=True)\n",
    "test.drop(columns=[\"sample\", \"price\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18417, 368), (3837, 367))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраним полученные датасеты для дальнейшего использования:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('train_numeric_tax.csv', index=False)\n",
    "test.to_csv('test_numeric_tax.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подбор гиперпараметров для каждой модели "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В стекинге будем использовать следующие модели: \n",
    "\n",
    "1. RandomForestRegressor\n",
    "\n",
    "2. ExtraTreesRegressor\n",
    "\n",
    "3. CatBoostRegressor\n",
    "\n",
    "4. LinearRegression\n",
    "\n",
    "Первые три модели будут представлять первый уровень, а линейная регрессия будет моделью второго уровня. Нами была рассмотрена также модель KNeighborsRegressor, но её использование в стекинге не дало улучшения. Перед тем как запускать процедуру стекинга, необходимо оптимизировать каждую из моделей, то есть подобрать гиперпараметры. Гиперпараметры для CatBoost были подобраны ранее, для линейной регрессии гиперпараметры подбираться не будут. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18417, 367), (3837, 367), (18417,))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train_numeric_tax.csv')\n",
    "test = pd.read_csv('test_numeric_tax.csv')\n",
    "y = train.price.values\n",
    "X_train = train.drop(['price'], axis=1)\n",
    "X_test = test\n",
    "X_train.shape, X_test.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем подбор параметров для модели RandomForestRegressor. Для этого специальным образом определим функцию скоринга mape, так как её нет среди стандартных функций. Из параметров будем определять количество деревьев, их глубину и нужен ли bootstrap для выборки. Эта часть кода запускалась на Kaggle, так как вычисления ресурсоемки, поэтому просто приведём результаты его работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(y_true, y_pred):\n",
    "    return -np.mean(np.abs((y_pred-y_true)/y_true))\n",
    "\n",
    "\n",
    "score = make_scorer(mape)\n",
    "\n",
    "param_grid = [\n",
    "    {'n_estimators': [100, 500, 1000],\n",
    "     'max_depth': [10, 50, None], 'bootstrap': [True, False]}\n",
    "]\n",
    "\n",
    "grid_search_forest = GridSearchCV(RandomForestRegressor(\n",
    "    n_jobs=-1), param_grid, cv=3, scoring=score, verbose=2)\n",
    "grid_search_forest.fit(X_train, y)\n",
    "grid_search_forest.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оптимальные параметры: n_estimators = 1000, max_depth = None, bootstrap = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Аналогичную операцию подбора проведём для ExtraTreesRegressor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {'n_estimators': [100, 500, 1000],\n",
    "     'max_depth': [10, 50, None], 'bootstrap': [True, False]}\n",
    "]\n",
    "\n",
    "grid_search_extra = GridSearchCV(ExtraTreesRegressor(\n",
    "    n_jobs=-1), param_grid, cv=3, scoring=score, verbose=2)\n",
    "grid_search_extra.fit(X_train, y)\n",
    "grid_search_extra.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оптимальные параметры: n_estimators = 1000, max_depth = None, bootstrap = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Стекинг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь всё готово для проведения стекинга. Воспользуемся для этого библиотекой **stacking**, которая была рекомендована в baseline. Вычисления также проводились на платформе Kaggle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_pred-y_true)/y_true))\n",
    "\n",
    "\n",
    "# Определим конфигурацию моделей\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "lr = LinearRegression(n_jobs=-1)\n",
    "\n",
    "etc = ExtraTreesRegressor(n_estimators=1000, bootstrap=True, n_jobs=-1,\n",
    "                          random_state=RANDOM_SEED)\n",
    "catb = CatBoostRegressor(iterations=3500,\n",
    "                         learning_rate=0.05,\n",
    "                         random_seed=RANDOM_SEED,\n",
    "                         eval_metric='MAPE',\n",
    "                         verbose=1000\n",
    "                         )\n",
    "rf = RandomForestRegressor(random_state=RANDOM_SEED, n_jobs=-1,\n",
    "                           n_estimators=1000, bootstrap=True)\n",
    "\n",
    "# Инициализируем модели 1-го уровня\n",
    "models = [rf, etc, catb]\n",
    "\n",
    "# Вычислим признаки для передачи в мета-модель\n",
    "S_train, S_test = stacking(models, X_train, y, X_test,\n",
    "                           regression=True, metric=mape, n_folds=4,\n",
    "                           shuffle=True, random_state=RANDOM_SEED, verbose=2)\n",
    "\n",
    "# Инициализируем модель 2 уровня (мета-модель)\n",
    "model = lr\n",
    "\n",
    "# Обучим\n",
    "model = model.fit(S_train, y)\n",
    "\n",
    "# Сделаем предсказание и запишем в файл (округление цены до тысяч приводит к незначительному улучшению качества)\n",
    "y_test_pred = np.exp(model.predict(S_test))\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "sample_submission['price'] = y_test_pred\n",
    "sample_submission['price'] = sample_submission['price'].apply(\n",
    "    lambda x: round(x/1000)*1000)\n",
    "sample_submission.to_csv('submission_stacking.csv', index=False)\n",
    "sample_submission.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Результаты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применение стекинга позволило улучшить результат модели до **10.52**, что, несомненно, является улучшением модели. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дополнительное исследование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Суть данного подхода состояла в том, чтобы сделать перестановки 4 используемых моделей так, чтобы каждый раз мета-модель была новой. Получились следующие результаты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meta_model</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>11.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>11.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoostRegressor</td>\n",
       "      <td>11.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LinearRegressor</td>\n",
       "      <td>10.52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              meta_model  score\n",
       "0    ExtraTreesRegressor  11.14\n",
       "1  RandomForestRegressor  11.20\n",
       "2      CatBoostRegressor  11.05\n",
       "3        LinearRegressor  10.52"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = pd.DataFrame({'meta_model': [\n",
    "                      \"ExtraTreesRegressor\",\n",
    "                      \"RandomForestRegressor\",\n",
    "                      \"CatBoostRegressor\",\n",
    "                      \"LinearRegressor\"],\n",
    "                      'score': [11.14, 11.20, 11.05, 10.52]})\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, все перестановки мета-моделей дали худший результат по сравнению с LinerarRegressor. Попытка осреднить все эти результаты не привела к улучшению, значение метрики после осреднения **10.79**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Финальный результат "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Финальный результат, отображаемый на лидерборде соревнования, равен **10.42**, что соответствует 14 месту из 57. Он получен не совсем честно, так как содержит элемент \"читерства\" (очень хотелось попробовать так сделать). Отметим, что он оставил нашу команду на том же месте лидерборда. Суть в том, что были взяты лучшие сабмиты и их scores, а дальше произведено осреднение результатов с весами, пропорциональными scores, чего, конечно, в \"боевых\" задачах сделать нельзя. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Stacking",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
